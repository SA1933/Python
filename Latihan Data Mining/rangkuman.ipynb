{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My Rangkuman Data Mining and Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# manipulasi data dalam bentuk tabel atau DataFrame.\n",
    "import seaborn as sns\n",
    "# memudahkan kamu membuat grafik seperti grafik garis, box plot, dan heatmap \n",
    "# dengan sedikit kode yang sering dikombinasikan dengan matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# visual\n",
    "import numpy as np\n",
    "# digunakan untuk manipulasi data dan pengolahan matriks\n",
    "from sklearn.model_selection import train_test_split\n",
    "# memilih training set dan test set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# klasifikasi dan pohon keputusan\n",
    "from sklearn.pipeline import Pipeline\n",
    "# memasukkan beberapa jalur atau anggap saja transformer atau estimatornya ke satu objek \n",
    "# atau satu jalur\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# search berdasarkan grid namun sebelumnya itu harus memasukkan parameter dan model\n",
    "from sklearn.metrics import accuracy_score\n",
    "# sesuai nama\n",
    "from sklearn.metrics import precision_score\n",
    "# sesuai nama\n",
    "from sklearn.metrics import recall_score\n",
    "# sesuai nama\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# sesuai nama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = (\"variabel dummy, jangan dianggap serius karena yang asli tetap pada program aslinya\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membuat persentase data yang hilang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[:,list(dataset.loc[:,dataset.isnull().any()].columns)].isnull().sum()/(len(dataset))*100\n",
    "#disini ada beberapa elemen yang perlu diperhatikan diantaranya adalah:\n",
    "# dataset.isnull().any()\n",
    "#>>>> didalamnya terdapat boolean True = kosong da False = ada\n",
    "# dataset.loc[:, ...].column\n",
    "#>>>> mengambil nama kolom-kolom yang memiliki value True sebagai sebuah daftar\n",
    "# dataset.loc[:, list(...)].isnull().sum()*100\n",
    "#>>>> intinnya membuat persentase dari len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memeriksa data yang konstan menggunakan Series.nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.loc[:,dataset.apply(pd.Series.nunique) != 1]\n",
    "# disini ada beberapa elemen yang perlu diperhatikan diantaranya adalah:\n",
    "# apply(pd.Series.nunique)\n",
    "#>>>> module dari panda yang mengembalikan nilai unik yang kemudian akan di masukkan kedalam series jumlah nilai uniknya\n",
    "# !=1\n",
    "#>>>> tidak sama dengan satu, True = jika tidak sama dengan 1 False = jika ada satu atau tidak ada\n",
    "# dataset.loc[:, ...]\n",
    "#>>>> menghasilkan DataFrame baru yang hanya berisi kolom-kolom yang memiiki lebih dari satu nilai unik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memeriksa data yang hilang dan membuat listnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col = [] # indexing\n",
    "for column in dataset.columns: # loop variabel dari column\n",
    "  if dataset[column].dtype == object and len(dataset[column].unique()) <= 50:\n",
    "    # check object dan nilai unik dari semua data dan menghitung panjang data tersebut\n",
    "    categorical_col.append(column) # ditambahkan ke kategorikal kolom\n",
    "    print(f\"{column} : {dataset[column].unique()}\") # mencetak kolom langsung dari kategorikal\n",
    "    print(\"\")\n",
    "# tambahan mengapa <=50: karena untuk memudahkan encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengganti data yang hilang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in dataset.columns:\n",
    "    if pd.api.types.is_numeric_dtype(dataset[column]): # set numeric True = yes False = no\n",
    "        dataset[column] = dataset[column].fillna(dataset[column].median()) # jika True isi memakai median\n",
    "    else:\n",
    "        dataset.loc[:, dataset.isnull().any()].columns # jika False maka langsung cek aja\n",
    "dataset.isna().sum() # memeriksa apakah value kosong telah terisi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_dt_pipeline = Pipeline([('model', DecisionTreeClassifier()), ])\n",
    "# [('model',DecisionTreeClassifier()),]\n",
    "# >>>> DTC model diproses pelatihan dan prediksi\n",
    "# Pipeline(...)\n",
    "# >>>> preprocessing, feature selection, atau modeling disusun alur pemrosesan data dan pelatihan mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dt = (\"variabel dummy, jangan dianggap serius karena yang asli tetap pada program aslinya\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV dari pipeline(\"parameter_dt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_classifier_dt = GridSearchCV(classifier_dt_pipeline, parameters_dt, cv=3, n_jobs=-1)\n",
    "# GridSearchCV(...)\n",
    "# >>>> cross-validation dari parameters_dt\n",
    "# classifier_dt_pipeline\n",
    "# >>>> menambahkan logika pipeline ke dalam GridSearchCV\n",
    "# parameters_dt\n",
    "# >>>> model parameternya max_depth, min_samples_leaf, criterion\n",
    "# cv=3\n",
    "# >>>> cross-validation fold, perbandingannya adalah 2 + 1 (2 pelatihan + 1 validasi)\n",
    "# n_jobs=-1\n",
    "# >>>> processor goes boom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (\"variabel dummy, jangan dianggap serius karena yang asli tetap pada program aslinya\")\n",
    "Y_train = (\"variabel dummy, jangan dianggap serius karena yang asli tetap pada program aslinya\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_classifier_dt.fit(X_train,Y_train.to_numpy())\n",
    "# .fit > setelah dijalankan akan mengeksekusi:>\n",
    "# >>>> ori_classifier_dt.best_params_ akan berisi parameter terbaik yang ditemukan oleh GridSearchCV\n",
    "# >>>> ori_classifier_dt.best_estimator_ akan berisi model Decision Tree yang sudah dilatih dengan parameter terbaik\n",
    "# >>>> ori_classifier_dt.predict() bisa digunakan untuk membuat prediksi pada data baru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "formatting nilai optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_name in sorted(parameters_dt.keys()): # looping nama parameter ke parameter_dt\n",
    "    print('%s: %r' %(param_name,ori_classifier_dt.best_params_[param_name]))\n",
    "    # '%s: %r' % (param_name, ori_classifier_dt.best_params_[param_name])\n",
    "    # >>>> string formatting di Python untuk mencetak setiap nama parameter (param_name) beserta nilai optimalnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = (\"variabel dummy, jangan dianggap serius karena yang asli tetap pada program aslinya\")\n",
    "Y_test = (\"variabel dummy, jangan dianggap serius karena yang asli tetap pada program aslinya\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediksi; Akurasi, Presisi dan Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_y_pred_dt_train = ori_classifier_dt.predict(X_train) # prediksi model train\n",
    "ori_accuracy_dt_train = accuracy_score(Y_train,ori_y_pred_dt_train) # akurasi skor model train\n",
    "ori_precision_dt_train = precision_score(Y_train,ori_y_pred_dt_train, average='micro') # presisi skor model train\n",
    "ori_recall_dt_train = recall_score(Y_train,ori_y_pred_dt_train, average='micro') # recall skor model train\n",
    "print('Akurasi pada training set: ', ori_accuracy_dt_train)\n",
    "print('Precision pada training set: ', ori_precision_dt_train)\n",
    "print('Recall pada training set: ', ori_recall_dt_train)\n",
    "\n",
    "ori_y_pred_dt_test = ori_classifier_dt.predict(X_test) # prediksi model test\n",
    "ori_accuracy_dt_test = accuracy_score(Y_test,ori_y_pred_dt_test) # akurasi model test\n",
    "ori_precision_dt_test = precision_score(Y_test,ori_y_pred_dt_test, average='micro') # presisi model test\n",
    "ori_recall_dt_test = recall_score(Y_test,ori_y_pred_dt_test, average='micro') # recall skor test\n",
    "print('Akurasi pada test set: ', ori_accuracy_dt_test)\n",
    "print('Precision pada test set: ', ori_precision_dt_test)\n",
    "print('Recall pada test set: ', ori_recall_dt_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
